import os
import datetime
import json


class agent_hyperparams(object):
    """ Class containing agent specific hyperparameters (for documentation purposes)

    :param agent_name: Precise agent name (as generated by get_agent_name())
    :param robot: Robot name to load robot specific .yaml file containing settings
    :param gamma: Discount factor
    :param n_steps: The number of steps to run for each environment per update
    :param ent_coef: Entropy coefficient for the loss calculation
    :param learning_rate: The learning rate, it can be a function
        of the current progress remaining (from 1 to 0)
        (i.e. batch size is n_steps * n_env where n_env is number of environment copies running in parallel)
    :param vf_coef: Value function coefficient for the loss calculation
    :param max_grad_norm: The maximum value for the gradient clipping
    :param gae_lambda: Factor for trade-off of bias vs variance for Generalized Advantage Estimator
    :param batch_size: Minibatch size
    :param n_epochs: Number of epoch when optimizing the surrogate loss
    :param clip_range: Clipping parameter, it can be a function of the current progress
        remaining (from 1 to 0).
    :param reward_fnc: Number of the reward function (defined in ../rl_agent/utils/reward.py)
    :param discrete_action_space: If robot uses discrete action space
    :param normalize: If observations are normalized before fed to the network
    :param task_mode: Mode tasks will be generated in (custom, random, staged).
    :param curr_stage: In case of staged training which stage to start with.
    :param n_timesteps: The number of timesteps trained on in total.
    """
    def __init__(self, agent_name: str, robot: str, gamma: float, n_steps: int, ent_coef: float, learning_rate: float, vf_coef: float, max_grad_norm: float, gae_lambda: float,
                 batch_size: int, n_epochs: int, clip_range: float, reward_fnc: str, discrete_action_space: bool, normalize: bool, task_mode: str, curr_stage: int = 0, n_timesteps: int = 0):
        self.agent_name = agent_name
        self.robot = robot 
        self.gamma = gamma 
        self.n_steps = n_steps
        self.ent_coef = ent_coef
        self.learning_rate = learning_rate
        self.vf_coef = vf_coef
        self.max_grad_norm = max_grad_norm
        self.gae_lambda = gae_lambda
        self.batch_size = batch_size
        self.n_epochs = n_epochs
        self.clip_range = clip_range
        self.reward_fnc = reward_fnc
        self.discrete_action_space = discrete_action_space
        self.normalize = normalize
        self.task_mode = task_mode
        self.curr_stage = curr_stage
        self.n_timesteps = n_timesteps


def initialize_hyperparameters(agent_name: str, PATHS: dict, hyperparams_obj: agent_hyperparams, load_target: str):
    """
    Write hyperparameters to json file in case agent is new otherwise load existing hyperparameters

    :param agent_name: agent name to save to/load from file system
    :param PATHS: dictionary containing model specific paths
    :param hyperparams_obj(object, agent_hyperparams): object containing containing model specific hyperparameters
    """
    if load_target is None:
        write_hyperparameters_json(hyperparams_obj, PATHS)
    hyperparams = load_hyperparameters_json(hyperparams_obj=hyperparams_obj,PATHS=PATHS)
    print_hyperparameters(hyperparams)
    return hyperparams


def write_hyperparameters_json(hyperparams_obj: agent_hyperparams, PATHS: dict):
    """
    Write hyperparameters to json file

    :param hyperparams_obj(object, agent_hyperparams): object containing containing model specific hyperparameters
    :param PATHS: dictionary containing model specific paths
    """
    doc_location = os.path.join(PATHS.get('model'), "hyperparameters.json")

    with open(doc_location, "w", encoding='utf-8') as target:
        json.dump(hyperparams_obj.__dict__, target, ensure_ascii=False, indent=4)


def load_hyperparameters_json(hyperparams_obj: agent_hyperparams, PATHS: dict):
    """
    Load hyperparameters from json file

    :param hyperparams_obj(object, agent_hyperparams): object containing containing model specific hyperparameters
    :param PATHS: dictionary containing model specific paths
    """
    doc_location = os.path.join(PATHS.get('model'), "hyperparameters.json")

    if os.path.isfile(doc_location):
        with open(doc_location, "r") as file:
            hyperparams = json.load(file)
        check_hyperparam_format(hyperparams_obj=hyperparams_obj, loaded_hyperparams=hyperparams, PATHS=PATHS)
        return hyperparams
    else:
        raise FileNotFoundError("Found no 'hyperparameters.json' in %s" % PATHS.get('model'))


def update_total_timesteps_json(hyperparams_obj: agent_hyperparams, timesteps: int, PATHS:dict):
    """
    Update total number of timesteps in json file

    :param hyperparams_obj(object, agent_hyperparams): object containing containing model specific hyperparameters
    :param PATHS: dictionary containing model specific paths
    """
    doc_location = os.path.join(PATHS.get('model'), "hyperparameters.json")
    hyperparams = load_hyperparameters_json(hyperparams_obj=hyperparams_obj, PATHS=PATHS)
    
    try:
        curr_timesteps = int(hyperparams['n_timesteps']) + timesteps
        hyperparams['n_timesteps'] = curr_timesteps
    except Exception:
        raise Warning("Parameter 'total_timesteps' not found or not of type Integer in 'hyperparameter.json'!")
    else:
        with open(doc_location, "w", encoding='utf-8') as target:
            json.dump(hyperparams, target, ensure_ascii=False, indent=4)
    

def print_hyperparameters(hyperparams_obj: agent_hyperparams):
    print("\n--------------------------------")
    print("         HYPERPARAMETERS         \n")
    for param, param_val in hyperparams_obj.items():
        print("{:25s}{:<10s}".format((param+":"), str(param_val)))
    print("--------------------------------\n\n")


def check_hyperparam_format(hyperparams_obj: agent_hyperparams, loaded_hyperparams: dict, PATHS: dict):
    """if not set(hyperparams_obj.__dict__.keys()) == set(loaded_hyperparams.keys()):
        raise AssertionError("'hyperparameters.json' in %s has unmatching keys" % PATHS.get('model'))"""
    if not isinstance(loaded_hyperparams['discrete_action_space'], bool):
        raise TypeError("Parameter 'discrete_action_space' not of type bool")
    if not loaded_hyperparams['task_mode'] in ["custom", "random", "staged"]:
        raise TypeError("Parameter 'task_mode' has unknown value")

